{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Dense, ELU, Flatten, Dropout, BatchNormalization,Add,GlobalAveragePooling2D,Softmax, Concatenate,add\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_datas = pd.read_csv(\"train.csv\")\n",
    "val_datas = pd.read_csv(\"Dig-MNIST.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(10240, 785)\n",
      "(70240, 785)\n"
     ]
    }
   ],
   "source": [
    "print(train_datas.shape)\n",
    "print(val_datas.shape)\n",
    "#train_datas = train_datas / 255.0\n",
    "#val_datas = val_datas / 255.0\n",
    "\n",
    "#concat train and val\n",
    "datas = pd.concat([train_datas,val_datas],axis=0)\n",
    "print(datas.shape)\n",
    "datas_X = np.array(datas.drop(\"label\",axis=1),dtype=np.float32)\n",
    "datas_Y = np.array(datas[[\"label\"]],dtype=np.int32)\n",
    "train_X,val_X,train_Y,val_Y = train_test_split(datas_X,datas_Y,test_size=0.2,shuffle=True)\n",
    "train_X2,val_X2,train_Y2,val_Y2 = train_test_split(datas_X,datas_Y,test_size=0.2,shuffle=True)\n",
    "train_X3,val_X3,train_Y3,val_Y3 = train_test_split(datas_X,datas_Y,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56192, 28, 28, 1) float32\n",
      "(56192, 1) int32\n",
      "(14048, 28, 28, 1) float32\n",
      "(14048, 1) int32\n"
     ]
    }
   ],
   "source": [
    "train_X = np.reshape(train_X,(-1,28,28,1))\n",
    "val_X = np.reshape(val_X,(-1,28,28,1))\n",
    "train_X2 = np.reshape(train_X2,(-1,28,28,1))\n",
    "val_X2 = np.reshape(val_X2,(-1,28,28,1))\n",
    "train_X3 = np.reshape(train_X3,(-1,28,28,1))\n",
    "val_X3 = np.reshape(val_X3,(-1,28,28,1))\n",
    "\n",
    "print(train_X.shape,train_X.dtype)\n",
    "print(train_Y.shape,train_Y.dtype)\n",
    "print(val_X.shape,val_X.dtype)\n",
    "print(val_Y.shape,val_Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "row,col,ch= (28,28,1)\n",
    "\n",
    "\n",
    "mean = 0\n",
    "var = 10\n",
    "sigma = var**0.4\n",
    "gauss = np.random.normal(mean,sigma,(train_X.shape[0],row,col,ch))\n",
    "gauss = gauss.reshape(train_X.shape[0],row,col,ch)\n",
    "noisy2 = train_X + gauss\n",
    "noisy2[noisy2>255] = 255\n",
    "noisy2[noisy2<0] = 0\n",
    "\n",
    "tmp_y = train_Y\n",
    "\n",
    "train_X = np.concatenate((train_X,noisy2))\n",
    "train_Y = np.concatenate((train_Y,tmp_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "row,col,ch= (28,28,1)\n",
    "\n",
    "mean = 0\n",
    "var = 10\n",
    "sigma = var**0.4\n",
    "gauss = np.random.normal(mean,sigma,(train_X2.shape[0],row,col,ch))\n",
    "gauss = gauss.reshape(train_X2.shape[0],row,col,ch)\n",
    "noisy2 = train_X2 + gauss\n",
    "noisy2[noisy2>255] = 255\n",
    "noisy2[noisy2<0] = 0\n",
    "\n",
    "tmp_y = train_Y2\n",
    "\n",
    "train_X2 = np.concatenate((train_X2,noisy2))\n",
    "train_Y2 = np.concatenate((train_Y2,tmp_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "row,col,ch= (28,28,1)\n",
    "\n",
    "mean = 0\n",
    "var = 10\n",
    "sigma = var**0.4\n",
    "gauss = np.random.normal(mean,sigma,(train_X3.shape[0],row,col,ch))\n",
    "gauss = gauss.reshape(train_X3.shape[0],row,col,ch)\n",
    "noisy2 = train_X3 + gauss\n",
    "noisy2[noisy2>255] = 255\n",
    "noisy2[noisy2<0] = 0\n",
    "\n",
    "tmp_y = train_Y3\n",
    "\n",
    "train_X3 = np.concatenate((train_X3,noisy2))\n",
    "train_Y3 = np.concatenate((train_Y3,tmp_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu_25 (ELU)                 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu_26 (ELU)                 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "elu_27 (ELU)                 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "elu_28 (ELU)                 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 7, 7, 196)         25284     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 7, 7, 196)         784       \n",
      "_________________________________________________________________\n",
      "elu_29 (ELU)                 (None, 7, 7, 196)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 7, 7, 10)          1970      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 7, 7, 10)          40        \n",
      "_________________________________________________________________\n",
      "elu_30 (ELU)                 (None, 7, 7, 10)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 288,732\n",
      "Trainable params: 287,552\n",
      "Non-trainable params: 1,180\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(28,28,1))\n",
    "net = Conv2D(64, (3,3), padding='same')(input_layer)\n",
    "net = BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\")(net)\n",
    "net = ELU(alpha=0.1)(net)\n",
    "\n",
    "net = Conv2D(64,  (3,3), padding='same')(net)\n",
    "net = BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\")(net)\n",
    "net = ELU(alpha=0.1)(net)\n",
    "\n",
    "net = MaxPooling2D(2, 2)(net)\n",
    "net = Dropout(0.2)(net)\n",
    "\n",
    "net = Conv2D(128,  (3,3), padding='same')(net)\n",
    "net = BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\")(net)\n",
    "net = ELU(alpha=0.1)(net)\n",
    "\n",
    "\n",
    "net = Conv2D(128,  (3,3), padding='same')(net)\n",
    "net = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\")(net)\n",
    "net = ELU(alpha=0.1)(net)\n",
    "\n",
    "\n",
    "net = MaxPooling2D(2, 2)(net)\n",
    "net = Dropout(0.2)(net)\n",
    "\n",
    "# net = Conv2D(196,  (3,3), padding='same')(net)\n",
    "# net = BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\")(net)\n",
    "# net = ELU(alpha=0.1)(net)\n",
    "\n",
    "\n",
    "net = Conv2D(196,  (1,1), padding='same')(net)\n",
    "net = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\")(net)\n",
    "net = ELU(alpha=0.1)(net)\n",
    "\n",
    "\n",
    "net = Conv2D(10,  (1,1), padding='same')(net)\n",
    "net = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\")(net)\n",
    "net = ELU(alpha=0.1)(net)\n",
    "\n",
    "net = GlobalAveragePooling2D()(net)\n",
    "\n",
    "output = Dense(10, activation='softmax')(net)\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu_31 (ELU)                 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu_32 (ELU)                 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "elu_33 (ELU)                 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "elu_34 (ELU)                 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 7, 7, 256)         819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "elu_35 (ELU)                 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 7, 7, 256)         65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "elu_36 (ELU)                 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 7, 7, 10)          2570      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 7, 7, 10)          40        \n",
      "_________________________________________________________________\n",
      "elu_37 (ELU)                 (None, 7, 7, 10)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 1,150,560\n",
      "Trainable params: 1,148,748\n",
      "Non-trainable params: 1,812\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(28,28,1))\n",
    "net2 = Conv2D(64, (3,3), padding='same')(input_layer)\n",
    "net2 = BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\")(net2)\n",
    "net2 = ELU(alpha=0.1)(net2)\n",
    "\n",
    "\n",
    "\n",
    "net2 = Conv2D(64,  (3,3), padding='same')(net2)\n",
    "net2 = BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\")(net2)\n",
    "net2 = ELU(alpha=0.1)(net2)\n",
    "\n",
    "\n",
    "net2 = MaxPooling2D(2, 2)(net2)\n",
    "net2 = Dropout(0.2)(net2)\n",
    "\n",
    "net2 = Conv2D(128,  (3,3), padding='same')(net2)\n",
    "net2 = BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\")(net2)\n",
    "net2 = ELU(alpha=0.1)(net2)\n",
    "\n",
    "\n",
    "net2 = Conv2D(128,  (3,3), padding='same')(net2)\n",
    "net2 = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\")(net2)\n",
    "net2 = ELU(alpha=0.1)(net2)\n",
    "\n",
    "\n",
    "net2 = MaxPooling2D(2, 2)(net2)\n",
    "net2 = Dropout(0.2)(net2)\n",
    "\n",
    "net2 = Conv2D(256,  (5,5), padding='same')(net2)\n",
    "net2 = BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\")(net2)\n",
    "net2 = ELU(alpha=0.1)(net2)\n",
    "\n",
    "\n",
    "net2 = Conv2D(256,  (1,1), padding='same')(net2)\n",
    "net2 = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\")(net2)\n",
    "net2 = ELU(alpha=0.1)(net2)\n",
    "\n",
    "\n",
    "net2 = Conv2D(10,  (1,1), padding='same')(net2)\n",
    "net2 = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\")(net2)\n",
    "net2 = ELU(alpha=0.1)(net2)\n",
    "\n",
    "net2 = GlobalAveragePooling2D()(net2)\n",
    "\n",
    "output = Dense(10, activation='softmax')(net2)\n",
    "model2 = Model(inputs=input_layer,outputs=output)\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu_38 (ELU)                 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu_39 (ELU)                 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "elu_40 (ELU)                 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "elu_41 (ELU)                 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 7, 7, 196)         25284     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 7, 7, 196)         784       \n",
      "_________________________________________________________________\n",
      "elu_42 (ELU)                 (None, 7, 7, 196)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 7, 7, 196)         38612     \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 7, 7, 196)         784       \n",
      "_________________________________________________________________\n",
      "elu_43 (ELU)                 (None, 7, 7, 196)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 7, 7, 10)          1970      \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 7, 7, 10)          40        \n",
      "_________________________________________________________________\n",
      "elu_44 (ELU)                 (None, 7, 7, 10)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 328,128\n",
      "Trainable params: 326,556\n",
      "Non-trainable params: 1,572\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(28,28,1))\n",
    "net3 = Conv2D(64, (3,3), padding='same')(input_layer)\n",
    "net3 = BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\")(net3)\n",
    "net3 = ELU(alpha=0.1)(net3)\n",
    "\n",
    "\n",
    "\n",
    "net3 = Conv2D(64,  (3,3), padding='same')(net3)\n",
    "net3 = BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\")(net3)\n",
    "net3 = ELU(alpha=0.1)(net3)\n",
    "\n",
    "\n",
    "net3 = MaxPooling2D(2, 2)(net3)\n",
    "net3 = Dropout(0.2)(net3)\n",
    "\n",
    "net3 = Conv2D(128,  (3,3), padding='same')(net3)\n",
    "net3 = BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\")(net3)\n",
    "net3 = ELU(alpha=0.1)(net3)\n",
    "\n",
    "\n",
    "net3 = Conv2D(128,  (3,3), padding='same')(net3)\n",
    "net3 = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\")(net3)\n",
    "net3 = ELU(alpha=0.1)(net3)\n",
    "\n",
    "\n",
    "net3 = MaxPooling2D(2, 2)(net3)\n",
    "net3 = Dropout(0.2)(net3)\n",
    "\n",
    "net3 = Conv2D(196,  (1,1), padding='same')(net3)\n",
    "net3 = BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\")(net3)\n",
    "net3 = ELU(alpha=0.1)(net3)\n",
    "\n",
    "\n",
    "net3 = Conv2D(196,  (1,1), padding='same')(net3)\n",
    "net3 = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\")(net3)\n",
    "net3 = ELU(alpha=0.1)(net3)\n",
    "\n",
    "\n",
    "net3 = Conv2D(10,  (1,1), padding='same')(net3)\n",
    "net3 = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\")(net3)\n",
    "net3 = ELU(alpha=0.1)(net3)\n",
    "\n",
    "net3 = GlobalAveragePooling2D()(net3)\n",
    "\n",
    "output = Dense(10, activation='softmax')(net3)\n",
    "model3 = Model(inputs=input_layer,outputs=output)\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 5,\n",
    "    width_shift_range = 0.12,\n",
    "    height_shift_range = 0.12,\n",
    "    shear_range = 0.1,\n",
    "    zoom_range = 0.15,\n",
    "    horizontal_flip = False,\n",
    "    rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='loss', \n",
    "                                            patience=3, \n",
    "                                            factor=0.4, \n",
    "                                            min_lr=0.000001)\n",
    "\n",
    "epochs = 60\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 2.1985 - acc: 0.4911 - val_loss: 2.0058 - val_acc: 0.7077\n",
      "Epoch 2/60\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 1.8058 - acc: 0.7550 - val_loss: 1.4809 - val_acc: 0.8632\n",
      "Epoch 3/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 1.3027 - acc: 0.9098 - val_loss: 0.9485 - val_acc: 0.9681\n",
      "Epoch 4/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.8624 - acc: 0.9647 - val_loss: 0.6047 - val_acc: 0.9742\n",
      "Epoch 5/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.5636 - acc: 0.9751 - val_loss: 0.3757 - val_acc: 0.9823\n",
      "Epoch 6/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.3724 - acc: 0.9805 - val_loss: 0.2419 - val_acc: 0.9853\n",
      "Epoch 7/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.2612 - acc: 0.9833 - val_loss: 0.1657 - val_acc: 0.9870\n",
      "Epoch 8/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.1908 - acc: 0.9854 - val_loss: 0.1230 - val_acc: 0.9883\n",
      "Epoch 9/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.1469 - acc: 0.9872 - val_loss: 0.0923 - val_acc: 0.9900\n",
      "Epoch 10/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.1188 - acc: 0.9883 - val_loss: 0.0774 - val_acc: 0.9898\n",
      "Epoch 11/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0988 - acc: 0.9894 - val_loss: 0.0647 - val_acc: 0.9904\n",
      "Epoch 12/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0841 - acc: 0.9904 - val_loss: 0.0546 - val_acc: 0.9916\n",
      "Epoch 13/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0731 - acc: 0.9911 - val_loss: 0.0517 - val_acc: 0.9920\n",
      "Epoch 14/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0641 - acc: 0.9916 - val_loss: 0.0439 - val_acc: 0.9924\n",
      "Epoch 15/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0573 - acc: 0.9921 - val_loss: 0.0410 - val_acc: 0.9921\n",
      "Epoch 16/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0525 - acc: 0.9926 - val_loss: 0.0386 - val_acc: 0.9922\n",
      "Epoch 17/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0474 - acc: 0.9930 - val_loss: 0.0339 - val_acc: 0.9932\n",
      "Epoch 18/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0459 - acc: 0.9926 - val_loss: 0.0324 - val_acc: 0.9933\n",
      "Epoch 19/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0417 - acc: 0.9933 - val_loss: 0.0322 - val_acc: 0.9918\n",
      "Epoch 20/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0381 - acc: 0.9937 - val_loss: 0.0275 - val_acc: 0.9942\n",
      "Epoch 21/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0351 - acc: 0.9941 - val_loss: 0.0272 - val_acc: 0.9939\n",
      "Epoch 22/60\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.0337 - acc: 0.9940 - val_loss: 0.0274 - val_acc: 0.9938\n",
      "Epoch 23/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0310 - acc: 0.9945 - val_loss: 0.0253 - val_acc: 0.9936\n",
      "Epoch 24/60\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.0292 - acc: 0.9946 - val_loss: 0.0250 - val_acc: 0.9935\n",
      "Epoch 25/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0278 - acc: 0.9948 - val_loss: 0.0233 - val_acc: 0.9939\n",
      "Epoch 26/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0269 - acc: 0.9950 - val_loss: 0.0251 - val_acc: 0.9936\n",
      "Epoch 27/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0261 - acc: 0.9950 - val_loss: 0.0220 - val_acc: 0.9943\n",
      "Epoch 28/60\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.0234 - acc: 0.9955 - val_loss: 0.0231 - val_acc: 0.9940\n",
      "Epoch 29/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0229 - acc: 0.9953 - val_loss: 0.0228 - val_acc: 0.9938\n",
      "Epoch 30/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0222 - acc: 0.9953 - val_loss: 0.0239 - val_acc: 0.9931\n",
      "Epoch 31/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0215 - acc: 0.9956 - val_loss: 0.0230 - val_acc: 0.9944\n",
      "Epoch 32/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0208 - acc: 0.9957 - val_loss: 0.0213 - val_acc: 0.9940\n",
      "Epoch 33/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0191 - acc: 0.9960 - val_loss: 0.0189 - val_acc: 0.9947\n",
      "Epoch 34/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0190 - acc: 0.9962 - val_loss: 0.0188 - val_acc: 0.9949\n",
      "Epoch 35/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0179 - acc: 0.9961 - val_loss: 0.0214 - val_acc: 0.9947\n",
      "Epoch 36/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0180 - acc: 0.9962 - val_loss: 0.0179 - val_acc: 0.9955\n",
      "Epoch 37/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0171 - acc: 0.9963 - val_loss: 0.0188 - val_acc: 0.9951\n",
      "Epoch 38/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0162 - acc: 0.9965 - val_loss: 0.0203 - val_acc: 0.9942\n",
      "Epoch 39/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0161 - acc: 0.9961 - val_loss: 0.0183 - val_acc: 0.9953\n",
      "Epoch 40/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0153 - acc: 0.9965 - val_loss: 0.0190 - val_acc: 0.9940\n",
      "Epoch 41/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0153 - acc: 0.9966 - val_loss: 0.0198 - val_acc: 0.9941\n",
      "Epoch 42/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0129 - acc: 0.9972 - val_loss: 0.0191 - val_acc: 0.9947\n",
      "Epoch 43/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0135 - acc: 0.9971 - val_loss: 0.0209 - val_acc: 0.9942\n",
      "Epoch 44/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0128 - acc: 0.9972 - val_loss: 0.0199 - val_acc: 0.9941\n",
      "Epoch 45/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0124 - acc: 0.9972 - val_loss: 0.0191 - val_acc: 0.9942\n",
      "Epoch 46/60\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0132 - acc: 0.9969 - val_loss: 0.0187 - val_acc: 0.9951\n",
      "Epoch 47/60\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.0123 - acc: 0.9969 - val_loss: 0.0175 - val_acc: 0.9948\n",
      "Epoch 48/60\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0119 - acc: 0.9973 - val_loss: 0.0160 - val_acc: 0.9948\n",
      "Epoch 49/60\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0123 - acc: 0.9970 - val_loss: 0.0168 - val_acc: 0.9953\n",
      "Epoch 50/60\n",
      "100/100 [==============================] - 18s 176ms/step - loss: 0.0119 - acc: 0.9971 - val_loss: 0.0190 - val_acc: 0.9939\n",
      "Epoch 51/60\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0193 - val_acc: 0.9937\n",
      "Epoch 52/60\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.0085 - acc: 0.9980 - val_loss: 0.0145 - val_acc: 0.9957\n",
      "Epoch 53/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.0147 - val_acc: 0.9953\n",
      "Epoch 54/60\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 0.0064 - acc: 0.9986 - val_loss: 0.0145 - val_acc: 0.9958\n",
      "Epoch 55/60\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.0061 - acc: 0.9988 - val_loss: 0.0154 - val_acc: 0.9952\n",
      "Epoch 56/60\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.0151 - val_acc: 0.9956\n",
      "Epoch 57/60\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0060 - acc: 0.9988 - val_loss: 0.0149 - val_acc: 0.9951\n",
      "Epoch 58/60\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 0.0065 - acc: 0.9986 - val_loss: 0.0151 - val_acc: 0.9956\n",
      "Epoch 59/60\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.0056 - acc: 0.9989 - val_loss: 0.0158 - val_acc: 0.9953\n",
      "Epoch 60/60\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0141 - val_acc: 0.9956\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(train_X,train_Y, batch_size=batch_size),\n",
    "                                    epochs = epochs, \n",
    "                                    steps_per_epoch = 100,\n",
    "                                    validation_data = (val_X/255.0,val_Y),\n",
    "                                    callbacks=[learning_rate_reduction],\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 2.1097 - acc: 0.7359 - val_loss: 1.8235 - val_acc: 0.9672\n",
      "Epoch 2/60\n",
      "100/100 [==============================] - 20s 203ms/step - loss: 1.5542 - acc: 0.9676 - val_loss: 1.1735 - val_acc: 0.9815\n",
      "Epoch 3/60\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 0.9406 - acc: 0.9851 - val_loss: 0.6268 - val_acc: 0.9895\n",
      "Epoch 4/60\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 0.5109 - acc: 0.9892 - val_loss: 0.3432 - val_acc: 0.9905\n",
      "Epoch 5/60\n",
      "100/100 [==============================] - 20s 200ms/step - loss: 0.2875 - acc: 0.9913 - val_loss: 0.1998 - val_acc: 0.9925\n",
      "Epoch 6/60\n",
      "100/100 [==============================] - 20s 200ms/step - loss: 0.1771 - acc: 0.9922 - val_loss: 0.1265 - val_acc: 0.9926\n",
      "Epoch 7/60\n",
      "100/100 [==============================] - 20s 200ms/step - loss: 0.1206 - acc: 0.9931 - val_loss: 0.0930 - val_acc: 0.9925\n",
      "Epoch 8/60\n",
      "100/100 [==============================] - 20s 201ms/step - loss: 0.0885 - acc: 0.9939 - val_loss: 0.0684 - val_acc: 0.9942\n",
      "Epoch 9/60\n",
      "100/100 [==============================] - 20s 203ms/step - loss: 0.0689 - acc: 0.9941 - val_loss: 0.0558 - val_acc: 0.9939\n",
      "Epoch 10/60\n",
      "100/100 [==============================] - 20s 203ms/step - loss: 0.0563 - acc: 0.9944 - val_loss: 0.0493 - val_acc: 0.9934\n",
      "Epoch 11/60\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 0.0462 - acc: 0.9948 - val_loss: 0.0429 - val_acc: 0.9939\n",
      "Epoch 12/60\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 0.0386 - acc: 0.9955 - val_loss: 0.0384 - val_acc: 0.9939\n",
      "Epoch 13/60\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 0.0339 - acc: 0.9958 - val_loss: 0.0340 - val_acc: 0.9940\n",
      "Epoch 14/60\n",
      "100/100 [==============================] - 19s 195ms/step - loss: 0.0297 - acc: 0.9956 - val_loss: 0.0359 - val_acc: 0.9922\n",
      "Epoch 15/60\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.0260 - acc: 0.9962 - val_loss: 0.0323 - val_acc: 0.9941\n",
      "Epoch 16/60\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.0234 - acc: 0.9967 - val_loss: 0.0278 - val_acc: 0.9947\n",
      "Epoch 17/60\n",
      "100/100 [==============================] - 19s 194ms/step - loss: 0.0213 - acc: 0.9966 - val_loss: 0.0264 - val_acc: 0.9946\n",
      "Epoch 18/60\n",
      "100/100 [==============================] - 19s 194ms/step - loss: 0.0199 - acc: 0.9967 - val_loss: 0.0234 - val_acc: 0.9950\n",
      "Epoch 19/60\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.0185 - acc: 0.9968 - val_loss: 0.0236 - val_acc: 0.9949\n",
      "Epoch 20/60\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 0.0171 - acc: 0.9969 - val_loss: 0.0229 - val_acc: 0.9950\n",
      "Epoch 21/60\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.0170 - acc: 0.9966 - val_loss: 0.0253 - val_acc: 0.9939\n",
      "Epoch 22/60\n",
      "100/100 [==============================] - 19s 194ms/step - loss: 0.0164 - acc: 0.9966 - val_loss: 0.0246 - val_acc: 0.9942\n",
      "Epoch 23/60\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.0142 - acc: 0.9973 - val_loss: 0.0218 - val_acc: 0.9950\n",
      "Epoch 24/60\n",
      "100/100 [==============================] - 19s 195ms/step - loss: 0.0131 - acc: 0.9974 - val_loss: 0.0219 - val_acc: 0.9946\n",
      "Epoch 25/60\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.0123 - acc: 0.9976 - val_loss: 0.0200 - val_acc: 0.9957\n",
      "Epoch 26/60\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 0.0115 - acc: 0.9977 - val_loss: 0.0210 - val_acc: 0.9943\n",
      "Epoch 27/60\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 0.0120 - acc: 0.9974 - val_loss: 0.0202 - val_acc: 0.9957\n",
      "Epoch 28/60\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.0109 - acc: 0.9976 - val_loss: 0.0185 - val_acc: 0.9955\n",
      "Epoch 29/60\n",
      "100/100 [==============================] - 19s 195ms/step - loss: 0.0095 - acc: 0.9979 - val_loss: 0.0225 - val_acc: 0.9941\n",
      "Epoch 30/60\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0218 - val_acc: 0.9948\n",
      "Epoch 31/60\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0209 - val_acc: 0.9949\n",
      "Epoch 32/60\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 0.0088 - acc: 0.9981 - val_loss: 0.0192 - val_acc: 0.9957\n",
      "Epoch 33/60\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 0.0090 - acc: 0.9977 - val_loss: 0.0211 - val_acc: 0.9946\n",
      "Epoch 34/60\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 0.0079 - acc: 0.9981 - val_loss: 0.0205 - val_acc: 0.9950\n",
      "Epoch 35/60\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.0093 - acc: 0.9977 - val_loss: 0.0225 - val_acc: 0.9952\n",
      "Epoch 36/60\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.0075 - acc: 0.9981 - val_loss: 0.0185 - val_acc: 0.9952\n",
      "Epoch 37/60\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 0.0078 - acc: 0.9981 - val_loss: 0.0204 - val_acc: 0.9949\n",
      "Epoch 38/60\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0189 - val_acc: 0.9954\n",
      "Epoch 39/60\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0207 - val_acc: 0.9947\n",
      "Epoch 40/60\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.0060 - acc: 0.9986 - val_loss: 0.0203 - val_acc: 0.9951\n",
      "Epoch 41/60\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.0064 - acc: 0.9984 - val_loss: 0.0211 - val_acc: 0.9954\n",
      "Epoch 42/60\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.0204 - val_acc: 0.9951\n",
      "Epoch 43/60\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.0200 - val_acc: 0.9949\n",
      "Epoch 44/60\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0181 - val_acc: 0.9960\n",
      "Epoch 45/60\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0175 - val_acc: 0.9954\n",
      "Epoch 46/60\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0180 - val_acc: 0.9958\n",
      "Epoch 47/60\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 0.0183 - val_acc: 0.9956\n",
      "Epoch 48/60\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.0029 - acc: 0.9994 - val_loss: 0.0188 - val_acc: 0.9953\n",
      "Epoch 49/60\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0173 - val_acc: 0.9961\n",
      "Epoch 50/60\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0201 - val_acc: 0.9952\n",
      "Epoch 51/60\n",
      "100/100 [==============================] - 20s 200ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0191 - val_acc: 0.9956\n",
      "Epoch 52/60\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0195 - val_acc: 0.9951\n",
      "Epoch 53/60\n",
      "100/100 [==============================] - 19s 195ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0212 - val_acc: 0.9947\n",
      "Epoch 54/60\n",
      "100/100 [==============================] - 21s 205ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0195 - val_acc: 0.9960\n",
      "Epoch 55/60\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0177 - val_acc: 0.9961\n",
      "Epoch 56/60\n",
      "100/100 [==============================] - 20s 201ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0193 - val_acc: 0.9959\n",
      "Epoch 57/60\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0198 - val_acc: 0.9954\n",
      "Epoch 58/60\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.0189 - val_acc: 0.9959\n",
      "Epoch 59/60\n",
      "100/100 [==============================] - 19s 194ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0177 - val_acc: 0.9964\n",
      "Epoch 60/60\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0178 - val_acc: 0.9962\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit_generator(datagen.flow(train_X2,train_Y2, batch_size=batch_size),\n",
    "                                    epochs = epochs, \n",
    "                                    steps_per_epoch = 100,\n",
    "                                    validation_data = (val_X2/255.0,val_Y2),\n",
    "                                    callbacks=[learning_rate_reduction],\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.0048 - acc: 0.9990 - val_loss: 0.0183 - val_acc: 0.9952\n",
      "Epoch 2/60\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0188 - val_acc: 0.9956\n",
      "Epoch 3/60\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0177 - val_acc: 0.9957\n",
      "Epoch 4/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0040 - acc: 0.9992 - val_loss: 0.0176 - val_acc: 0.9960\n",
      "Epoch 5/60\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 0.0191 - val_acc: 0.9954\n",
      "Epoch 6/60\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.0042 - acc: 0.9991 - val_loss: 0.0205 - val_acc: 0.9953\n",
      "Epoch 7/60\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.0183 - val_acc: 0.9952\n",
      "Epoch 8/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0034 - acc: 0.9993 - val_loss: 0.0177 - val_acc: 0.9954\n",
      "Epoch 9/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0177 - val_acc: 0.9957\n",
      "Epoch 10/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.0178 - val_acc: 0.9961\n",
      "Epoch 11/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.0194 - val_acc: 0.9959\n",
      "Epoch 12/60\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0180 - val_acc: 0.9959\n",
      "Epoch 13/60\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.0178 - val_acc: 0.9957\n",
      "Epoch 14/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0029 - acc: 0.9994 - val_loss: 0.0183 - val_acc: 0.9957\n",
      "Epoch 15/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0028 - acc: 0.9994 - val_loss: 0.0183 - val_acc: 0.9956\n",
      "Epoch 16/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 0.0184 - val_acc: 0.9957\n",
      "Epoch 17/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0183 - val_acc: 0.9957\n",
      "Epoch 18/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0177 - val_acc: 0.9957\n",
      "Epoch 19/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0178 - val_acc: 0.9958\n",
      "Epoch 20/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0183 - val_acc: 0.9959\n",
      "Epoch 21/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0176 - val_acc: 0.9959\n",
      "Epoch 22/60\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0187 - val_acc: 0.9956\n",
      "Epoch 23/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0185 - val_acc: 0.9954\n",
      "Epoch 24/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0180 - val_acc: 0.9956\n",
      "Epoch 25/60\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0178 - val_acc: 0.9958\n",
      "Epoch 26/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0174 - val_acc: 0.9959\n",
      "Epoch 27/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0180 - val_acc: 0.9956\n",
      "Epoch 28/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0179 - val_acc: 0.9957\n",
      "Epoch 29/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0175 - val_acc: 0.9959\n",
      "Epoch 30/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0179 - val_acc: 0.9959\n",
      "Epoch 31/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0178 - val_acc: 0.9956\n",
      "Epoch 32/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0177 - val_acc: 0.9957\n",
      "Epoch 33/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0181 - val_acc: 0.9957\n",
      "Epoch 34/60\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0180 - val_acc: 0.9959\n",
      "Epoch 35/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0180 - val_acc: 0.9957\n",
      "Epoch 36/60\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0177 - val_acc: 0.9959\n",
      "Epoch 37/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0180 - val_acc: 0.9957\n",
      "Epoch 38/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0185 - val_acc: 0.9959\n",
      "Epoch 39/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0178 - val_acc: 0.9957\n",
      "Epoch 40/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0185 - val_acc: 0.9959\n",
      "Epoch 41/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0178 - val_acc: 0.9957\n",
      "Epoch 42/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0181 - val_acc: 0.9959\n",
      "Epoch 43/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0179 - val_acc: 0.9960\n",
      "Epoch 44/60\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0179 - val_acc: 0.9957\n",
      "Epoch 45/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0180 - val_acc: 0.9957\n",
      "Epoch 46/60\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0179 - val_acc: 0.9956\n",
      "Epoch 47/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0021 - acc: 0.9997 - val_loss: 0.0179 - val_acc: 0.9958\n",
      "Epoch 48/60\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 0.0021 - acc: 0.9997 - val_loss: 0.0179 - val_acc: 0.9958\n",
      "Epoch 49/60\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0176 - val_acc: 0.9957\n",
      "Epoch 50/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0176 - val_acc: 0.9957\n",
      "Epoch 51/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0021 - acc: 0.9997 - val_loss: 0.0180 - val_acc: 0.9959\n",
      "Epoch 52/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0019 - acc: 0.9998 - val_loss: 0.0178 - val_acc: 0.9957\n",
      "Epoch 53/60\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0180 - val_acc: 0.9957\n",
      "Epoch 54/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0178 - val_acc: 0.9958\n",
      "Epoch 55/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0179 - val_acc: 0.9958\n",
      "Epoch 56/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0180 - val_acc: 0.9959\n",
      "Epoch 57/60\n",
      "100/100 [==============================] - 18s 176ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0176 - val_acc: 0.9959\n",
      "Epoch 58/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0183 - val_acc: 0.9956\n",
      "Epoch 59/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0181 - val_acc: 0.9958\n",
      "Epoch 60/60\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0177 - val_acc: 0.9959\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit_generator(datagen.flow(train_X2,train_Y2, batch_size=batch_size),\n",
    "                                    epochs = epochs, \n",
    "                                    steps_per_epoch = 100,\n",
    "                                    validation_data = (val_X2/255.0,val_Y2),\n",
    "                                    callbacks=[learning_rate_reduction],\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DNN = np.zeros( (train_X.shape[0],30))\n",
    "train_model1 = model.predict(train_X/255.)\n",
    "train_model2 = model2.predict(train_X/255.)\n",
    "train_model3 = model3.predict(train_X/255.)\n",
    "\n",
    "train_model1 = train_model1.reshape(train_model1.shape[0],10)\n",
    "train_model2 = train_model2.reshape(train_model2.shape[0],10)\n",
    "train_model3 = train_model3.reshape(train_model3.shape[0],10)\n",
    "\n",
    "\n",
    "train_DNN = np.concatenate((train_model1, train_model2), axis=1)\n",
    "train_DNN = np.concatenate((train_DNN, train_model3), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_DNN = np.zeros( (val_X.shape[0],30))\n",
    "results1 = np.zeros( (val_X.shape[0],10))\n",
    "results2 = np.zeros( (val_X.shape[0],10))\n",
    "results3 = np.zeros( (val_X.shape[0],10))\n",
    "\n",
    "val_model1 =   model.predict(val_X/255.)\n",
    "val_model2 =  model2.predict(val_X/255.)\n",
    "val_model3 =  model3.predict(val_X/255.)\n",
    "\n",
    "\n",
    "val_model1 = val_model1.reshape(val_model1.shape[0],10)\n",
    "val_model2 = val_model2.reshape(val_model2.shape[0],10)\n",
    "val_model3 = val_model3.reshape(val_model3.shape[0],10)\n",
    "\n",
    "val_DNN = np.concatenate((val_model1, val_model2), axis=1)\n",
    "val_DNN = np.concatenate((val_DNN, val_model3), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112384, 30)\n",
      "(14048, 30)\n"
     ]
    }
   ],
   "source": [
    "print(train_DNN.shape)\n",
    "print(val_DNN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 18)                558       \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 18)                72        \n",
      "_________________________________________________________________\n",
      "elu_23 (ELU)                 (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 18)                72        \n",
      "_________________________________________________________________\n",
      "elu_24 (ELU)                 (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                190       \n",
      "=================================================================\n",
      "Total params: 1,234\n",
      "Trainable params: 1,162\n",
      "Non-trainable params: 72\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(30,))\n",
    "\n",
    "net_dnn = Dense(18)(input_layer)\n",
    "net_dnn = BatchNormalization()(net_dnn)\n",
    "net_dnn = ELU(alpha=0.1)(net_dnn)\n",
    "\n",
    "net = Dropout(0.2)(net)\n",
    "net_dnn = Dense(18)(net_dnn)\n",
    "net_dnn = BatchNormalization()(net_dnn)\n",
    "net_dnn = ELU(alpha=0.1)(net_dnn)\n",
    "\n",
    "output = Dense(10, activation='softmax')(net_dnn)\n",
    "model_dnn = Model(inputs=input_layer,outputs=output)\n",
    "print(model_dnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112384 samples, validate on 14048 samples\n",
      "Epoch 1/24\n",
      "112384/112384 [==============================] - 1s 13us/sample - loss: 1.3040 - acc: 0.6892 - val_loss: 1.4931 - val_acc: 0.9981\n",
      "Epoch 2/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.2924 - acc: 0.9995 - val_loss: 0.5747 - val_acc: 0.9979\n",
      "Epoch 3/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.1016 - acc: 0.9995 - val_loss: 0.1617 - val_acc: 0.9981\n",
      "Epoch 4/24\n",
      "112384/112384 [==============================] - 1s 9us/sample - loss: 0.0518 - acc: 0.9995 - val_loss: 0.0600 - val_acc: 0.9981\n",
      "Epoch 5/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0317 - acc: 0.9996 - val_loss: 0.0334 - val_acc: 0.9981\n",
      "Epoch 6/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0215 - acc: 0.9996 - val_loss: 0.0239 - val_acc: 0.9981\n",
      "Epoch 7/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0154 - acc: 0.9997 - val_loss: 0.0193 - val_acc: 0.9981\n",
      "Epoch 8/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0116 - acc: 0.9997 - val_loss: 0.0167 - val_acc: 0.9981\n",
      "Epoch 9/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0091 - acc: 0.9998 - val_loss: 0.0151 - val_acc: 0.9981\n",
      "Epoch 10/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0074 - acc: 0.9998 - val_loss: 0.0141 - val_acc: 0.9979\n",
      "Epoch 11/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0061 - acc: 0.9998 - val_loss: 0.0135 - val_acc: 0.9979\n",
      "Epoch 12/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0050 - acc: 0.9998 - val_loss: 0.0131 - val_acc: 0.9978\n",
      "Epoch 13/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0043 - acc: 0.9998 - val_loss: 0.0128 - val_acc: 0.9977\n",
      "Epoch 14/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0037 - acc: 0.9999 - val_loss: 0.0128 - val_acc: 0.9976\n",
      "Epoch 15/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0032 - acc: 0.9999 - val_loss: 0.0129 - val_acc: 0.9976\n",
      "Epoch 16/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0028 - acc: 0.9999 - val_loss: 0.0129 - val_acc: 0.9975\n",
      "Epoch 17/24\n",
      "112384/112384 [==============================] - 1s 9us/sample - loss: 0.0025 - acc: 0.9999 - val_loss: 0.0130 - val_acc: 0.9974\n",
      "Epoch 18/24\n",
      "112384/112384 [==============================] - 1s 9us/sample - loss: 0.0022 - acc: 0.9999 - val_loss: 0.0132 - val_acc: 0.9974\n",
      "Epoch 19/24\n",
      "112384/112384 [==============================] - 1s 9us/sample - loss: 0.0020 - acc: 0.9999 - val_loss: 0.0133 - val_acc: 0.9974\n",
      "Epoch 20/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0018 - acc: 0.9999 - val_loss: 0.0134 - val_acc: 0.9973\n",
      "Epoch 21/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0136 - val_acc: 0.9972\n",
      "Epoch 22/24\n",
      "112384/112384 [==============================] - 1s 8us/sample - loss: 0.0015 - acc: 0.9999 - val_loss: 0.0137 - val_acc: 0.9973\n",
      "Epoch 23/24\n",
      "112384/112384 [==============================] - 1s 9us/sample - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0139 - val_acc: 0.9973\n",
      "Epoch 24/24\n",
      "112384/112384 [==============================] - 1s 9us/sample - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0140 - val_acc: 0.9973\n"
     ]
    }
   ],
   "source": [
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "history_dnn = model_dnn.fit(train_DNN,train_Y, batch_size=batch_size,\n",
    "                                    epochs = 24, \n",
    "                                    #steps_per_epoch = 72,\n",
    "                                    validation_data = (val_DNN,val_Y),\n",
    "                                    #callbacks=[learning_rate_reduction],\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_DNN = np.zeros( (val_X.shape[0],30))\n",
    "results1 = np.zeros( (val_X.shape[0],10))\n",
    "results2 = np.zeros( (val_X.shape[0],10))\n",
    "results3 = np.zeros( (val_X.shape[0],10))\n",
    "\n",
    "results1 = results1 + model.predict(val_X/255.)\n",
    "results2= results2 + model2.predict(val_X/255.)\n",
    "results3 = results3 + model3.predict(val_X/255.)\n",
    "\n",
    "val_model1 = np.argmax(results1,axis = 1)\n",
    "val_model2 = np.argmax(results2,axis = 1)\n",
    "val_model3 = np.argmax(results3,axis = 1)\n",
    "\n",
    "val_model1 = val_model1.reshape(val_model1.shape[0],1)\n",
    "val_model2 = val_model2.reshape(val_model2.shape[0],1)\n",
    "val_model3 = val_model3.reshape(val_model3.shape[0],1)\n",
    "\n",
    "val_DNN = np.concatenate((val_model1, val_model2), axis=1)\n",
    "val_DNN = np.concatenate((val_DNN, val_model3), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992881548974943\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "labels_v = scipy.stats.mode(val_DNN, axis=1,nan_policy='propagate')[0]\n",
    "\n",
    "labels_v = np.squeeze(labels_v)\n",
    "labels_v = labels_v.reshape(val_Y.shape)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(labels_v, val_Y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "test_csv = pd.read_csv(\"../input/Kannada-MNIST/test.csv\")\n",
    "data_test = np.array(test_csv.drop(\"id\",axis=1),dtype=np.float32)\n",
    "data_test = np.reshape(data_test,(-1,28,28,1))\n",
    "X_test = data_test / 255.0\n",
    "#X_test = data_test\n",
    "print(X_test.shape,X_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_DNN = np.zeros( (X_test.shape[0],30))\n",
    "test1 = np.zeros( (X_test.shape[0],10))\n",
    "test2 = np.zeros( (X_test.shape[0],10))\n",
    "test3 = np.zeros( (X_test.shape[0],10))\n",
    "\n",
    "test1 = test1 + model.predict(X_test)\n",
    "test2 = test2 + model2.predict(X_test)\n",
    "test3 = test3 + model3.predict(X_test)\n",
    "\n",
    "test1_ = np.argmax(test1,axis = 1)\n",
    "test2_ = np.argmax(test2,axis = 1)\n",
    "test3_ = np.argmax(test3,axis = 1)\n",
    "\n",
    "test1_ = test1_.reshape(test1_.shape[0],1)\n",
    "test2_ = test2_.reshape(test2_.shape[0],1)\n",
    "test3_ = test3_.reshape(test3_.shape[0],1)\n",
    "\n",
    "test_DNN = np.concatenate((test1_, test2_), axis=1)\n",
    "test_DNN = np.concatenate((test_DNN, test3_), axis=1)\n",
    "\n",
    "labels_test = scipy.stats.mode(test_DNN, axis=1,nan_policy='propagate')[0]\n",
    "\n",
    "labels_test = np.squeeze(labels_test)\n",
    "labels_test = labels_test.reshape((X_test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../input/Kannada-MNIST/sample_submission.csv\")\n",
    "submission['label'] = labels_test\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
